{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp6fW8MP-mrO"
   },
   "source": [
    "# 트리의 앙상블\n",
    "* 앙상블 학습법은 더 좋은 예측 성능을 얻기위해 다수의 학습 알고리즘을 사용하는 방법이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIaIAizcRSG-"
   },
   "source": [
    "## 랜덤포레스트\n",
    "* 결정트리를 랜덤하게 만들어 결정트리(나무)의 숲을 만든다\n",
    "* 랜덤 포레스트는 각 트리를 훈련하기 위한 데이터를 랜덤하게 만드는데 한 샘플이 중복되어 추출될 수도 있다\n",
    "* 중복되어서 만들어진 샘플을 부트스트랩 샘플 이라고 한다\n",
    "* 부트스트랩 샘플은 훈련세트의 크기와 같게 만들어서 각각의 부트스트랩 샘플별로 결정트리훈련을 수행한다\n",
    "* RandomForestClassifier는 전체 특성개수의 제곱근 만큼의 특성을 선택하여 사용한다. \n",
    "* RandomForestRegressor는 전체 특성을 사용한다\n",
    "* 랜덤포레스트는 기본적으로 100개의 결정트리를 훈련합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ioJUlZ0M_uSZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5197, 3) (5197,)\n",
      "(1300, 3) (1300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.read_csv('data/wine/wine.csv')\n",
    "\n",
    "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
    "target = wine['class'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기본적으로 100개의 결정트리를 사용하므로 n_jobs를 -1 로 지정하여 모든 CPU 코어를 사용하는 것이 좋다\n",
    "* cross_validate() 함수에서 return_train_score 매개변수를 True로 지정하면 훈련세트에 대한 점수도 검증세트 점수와 같이 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDKQudr7_8nu",
    "outputId": "cf7b1ac6-298b-466d-c76a-85e1f1a48fb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973541965122431 0.8905151032797809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(rf, X_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYDbzXNLG8fK",
    "outputId": "4327840f-5627-44f6-e3aa-480724095577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23167441 0.50039841 0.26792718]\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 부트스트랩에 샘플에 포함되지 않고 남는 샘플을 OOB(out of bag) 샘플이라고 한다\n",
    "* OOB 샘플을 사용하여 부트스트랩 샘플로 훈련한 결정트리를 평가할 수 있다\n",
    "* 교차검증세트에서 얻은 점수가 비슷한 결과가 나온다  0.8905151032797809 / 0.8934000384837406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMc06S1Fa_A-",
    "outputId": "48fda97e-0e01-4412-b15a-df0e32d167a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8934000384837406\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdrVoeQZRU14"
   },
   "source": [
    "## 엑스트라트리\n",
    "* 랜덤 포레스트와 비슷하게 동작한다 차이점은 부트스트랩 샘플을 사용하지 않는다\n",
    "* 엑스트라 트리가 사용하는 결정트리가 splitter='random' 인 결정트리이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noMLdywdOGrE",
    "outputId": "c47db8c9-00e7-4950-b6c1-158985b050f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9974503966084433 0.8887848893166506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(et, X_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnB0_mBqfcXL",
    "outputId": "ca587488-284d-4754-9080-7f1f0bd5782f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20183568 0.52242907 0.27573525]\n"
     ]
    }
   ],
   "source": [
    "et.fit(X_train, y_train)\n",
    "print(et.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csKxnaxeRX8s"
   },
   "source": [
    "## 그레디언트 부스팅\n",
    "* 그레디언트 부스팅은 깊이가 얕은 결정트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블 하는 방법이다\n",
    "* Scikit-Learn의 GradientBoostingClassifier는 깊이가 3인 결정트리를 100개 사용한다\n",
    " - 깊이가 얕은 결정트리를 사용하기 때문에 과대적합에 강하고, 높은 일반화 성능을 기대할 수 있다\n",
    "* 경사하강법을 사용하여 트리를 앙상블에 추가한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_IlNEFkaNsoG",
    "outputId": "58b3058f-d762-40c2-920d-f41280897ee0"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(gb, X_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* n_estimators는 결정트리의 갯수이다. \n",
    "* 결정트리 갯수를 5배나 늘렸지만 과대적합을 잘 억제한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNpeS8EWpeEi",
    "outputId": "6c35dc14-01a6-4413-bc92-41f3117551ab"
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
    "scores = cross_validate(gb, X_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그레이언트 부스팅이 랜덤 포레스트 보다 당도(sugar)에 좀 더 집중한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qD6iWVsGqCAE",
    "outputId": "d1bf677a-57e8-4c39-e8db-e15a9e0b8736"
   },
   "outputs": [],
   "source": [
    "gb.fit(X_train, y_train)\n",
    "print(gb.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BthW_II9RbLa"
   },
   "source": [
    "## 히스토그램 기반 부스팅\n",
    "* 그레디언트 부스팅이 랜덤 포레스트 보다 좀 더 높은 성능을 내지만 순서대로 트리를 추가하지 때문에 속도가 느리며, n_jobs 매개변수도 없다\n",
    "* 그레디언트 부스팅의 속도와 성능을 개선한 모델이 히스토그램기반 부스팅이다\n",
    "* 히스토그램기반 부스팅은 입력 특성(feature)를 256개의 구간으로 나누기 때문에 노드를 분할할때 최적의 분할을 매우 빠르게 찾을 수 있다\n",
    "* HistGradientBoostingClassifier 아직 테스트 과정에 있기 때문에 이 클래스를 사용하려면 sklearn.experimental 패키지 아래에 있는 enable_hist_gradient_boosting 모듈을 같이 import 해야 한다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3Ct_NNWQbdA",
    "outputId": "1d1c3a89-da88-4de2-e18d-231be60196c2"
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(hgb, X_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Permutation Importance는 모델을 학습시킨 뒤, 특정 feature의 데이터를 shuffle 했을 때, 검증 데이터 셋에 대한 예측성능을 확인하고 feature importance를 계산한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TvlB0GMTS3hn",
    "outputId": "573bc7ab-9296-4fac-f3c7-7287272b59e2"
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "hgb.fit(train_input, train_target)\n",
    "result = permutation_importance(hgb, X_train, y_train, n_repeats=10,\n",
    "                                random_state=42, n_jobs=-1)\n",
    "print(result.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8FfxInn-xBQ",
    "outputId": "cc66a246-0949-40b4-d189-666ee1c571c6"
   },
   "outputs": [],
   "source": [
    "result = permutation_importance(hgb, test_input, test_target, n_repeats=10,\n",
    "                                random_state=42, n_jobs=-1)\n",
    "print(result.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqplZjh0j2nw",
    "outputId": "39f4cf40-a390-41ae-f456-85e26b10d4ba"
   },
   "outputs": [],
   "source": [
    "hgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fz_FrezBezR"
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBYLvOiV6rga",
    "outputId": "ab3d60b8-36ea-4fc0-d1c6-30e0449ceb8e"
   },
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
    "# scores = cross_validate(xgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "# print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zl6nh6DOBd-B"
   },
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "maihlDMP7lmY",
    "outputId": "d277c10f-0123-427e-abea-8e4a7041d36b"
   },
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# lgb = LGBMClassifier(random_state=42)\n",
    "# scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "# print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5-3 트리의 앙상블.ipynb의 사본",
   "provenance": [
    {
     "file_id": "https://github.com/rickiepark/hg-mldl/blob/master/5-3.ipynb",
     "timestamp": 1615908119116
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
