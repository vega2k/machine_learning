머신러닝의 분류
 : 지도학습과 비지도학습으로 나누어진다.
   - 지도학습은 독립변수와 종속변수(레이블)이 있는 데이터를 학습하는 방법
   - 비지도학습은 독립변수 만 있는 데이터를 학습하는 방법
       : 데이터의 구조를 파악할 때 주로 사용한다

 : 지도학습은 분류(classification)와 회귀(Regression)을 나누어진다.
    예측해야 하는 값이 범주형데이터 이면 분류이고,
    예측해야 하는 값이 숫자데이터 이면 회귀이다

독립변수와 종속변수 
독립변수 - 입력데이터
종속변수 - 레이블(답)

y = f(x)
x는 입력데이터, y=출력값

훈련데이터 - 훈련할때 사용하는 데이터
   독립변수와 종속변수 

  독립변수 - 꽃받침의 길이와 폭, 꽃잎의 길이와 폭
  종속변수 - 품종명

  훈련데이터의 독립변수 X_train
  훈련데이터의 종속변수 y_train
  #학습하기
  model.fit(X_train, y_train)

테스트데이터 - 훈련을 잘 했는지 평가할 때 사용하는 데이터
  독립변수 / 예측한 값 
  종속변수 (답)

  테스트데이터의 독립변수 X_test
  테스트데이터의 종속변수 y_test
  
  #예측하기
 prediction =  model.predict(X_test)
  
 prediction와 y_test 비교해서 점수를 확인

  테스트 데이터의 종속변수가 실체로 예측해야 하는 값
  kaggle에서 제공하는 테스트데이터에는 종속변수(레이블)이 없다

k-최근접이웃 알고리즘 분류/회귀 
KNeighborsClassifier (iris, cancer)
KNeighborsRegressor (fish)

과대적합 / 과소적합?

과소적합
훈련 데이터 score
0.9698823289099254 (k=5)
0.9804899950518966 (k=3)

테스트 데이터 score
0.992809406101064 (k=5)
0.9746459963987609 (k=3)


회귀(Regression)
:  무게(weight) 예측
1. KNN 알고리즘 한계
: KNeighborsRegressor 클래스 사용
 - k는 가장 가까운 이웃의 갯수 
   : 사용자가 매개변수로 입력해야 하는 파라미터 - 하이퍼파라미터
 - 예측을 할때 가장 가까운 거리의 이웃의 데이터를 평균값으로 예측한다

2. 선형회귀
: LinearRegression 클래스 사용
y = ax + b  일차방정식
x 는 입력(길이), y 예측한값(무게)
a는 가중치(weight), b는 절편(bias)
a,b는 모델이 학습을 하면서 찾은 파라미터 - 모델파라미터 

다항회귀
y = ax2 + bx + c  이차방정식
a,b는 가중치, c는 절편

다중회귀
데이터 처리
-feature의 갯수를 늘리기 위해서 PolynomialFeatures 클래스 사용

-feature 를 정규화 하기 위해서 StandardScaler 클래스 사용
-가중치의 개수를 줄이기 위해서 규제를 적용한 Ridge, Lasso 클래스를 사용







  